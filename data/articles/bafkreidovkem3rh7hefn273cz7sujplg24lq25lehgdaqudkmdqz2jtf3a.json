{
  "postTime": 1761282322000,
  "authorId": "0xde272e0cce4e53377d40205d1f6e115099feb2cf",
  "tags": [
    "Technology",
    "Opinion"
  ],
  "title": "Stop Giving us Nude Tayne",
  "preview": "Two visions for the Age of AI",
  "body": "*New to Taming Complexity? Learn about our approach to collective intelligence and managing the complexity of technological change* *[here](https://tamingcomplexity.substack.com/about).*\n\n***\n\nStrange, is it not? Given that disagreement is an indisputable fact of the human condition, when a powerful technology so complex that its creators do not even fully understand how it works is unleashed into almost every sector of society with little concern for the consequences or understanding of the risks, one might expect a wide range of responses to emerge. And yet, two deterministic narratives basically dominate the discourse around AI.\n\nOn the one hand, Boosters promise a future to dream about, where dull, dirty, and dangerous jobs are handled by robots, leaving each of us to pursue our interests with a fleet of powerful digital assistants at our beck and call. (Bracket for now the fact that in the same breath, they add that each of us will have to rapidly adapt and [optimize to thrive](https://abitgamey.substack.com/p/thriving-with-ai-15-kevin-kelly-tips) in this brave new Age of AI—or risk being left behind.)\n\nOn the other, Doomsters, including Nobel Laureate [Geoffry Hinton,](https://edition.cnn.com/2025/08/13/tech/ai-geoffrey-hinton) one of the so-called “AI godfathers” who developed many of the techniques behind the current boom, warn that utter disaster, even extinction itself, awaits us. The title of a recent Doomster manifesto sums it up: _[If Anyone Builds It Everyone Dies](https://en.wikipedia.org/wiki/If_Anyone_Builds_It,_Everyone_Dies)_.\n\n[![](https://substackcdn.com/image/fetch/$s_!nEZt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7de00374-62a4-4c75-b0b9-479b3e5a56c5_1024x608.png)](https://substackcdn.com/image/fetch/$s_!nEZt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7de00374-62a4-4c75-b0b9-479b3e5a56c5_1024x608.png)\n\n{{caption:For such a complicated technology, thinking about AI is suspiciously simplistic.}}\n\nBoosters and Doomsters have polarized the discourse into deadlock, yet technical progress proceeds apace, with new advances [each week](https://www.tomsguide.com/ai/7-major-ai-updates-this-week-including-one-that-could-change-search-forever). Society still hasn’t figured out what to do about deepfakes—but have you seen the new [videos generated on Sora 2](https://www.youtube.com/watch?v=ZwnBxuPLwAY)? No robust protections for minors exist and [real harms](https://edition.cnn.com/2025/08/26/tech/openai-chatgpt-teen-suicide-lawsuit) are emerging—but chatbot usage is higher than ever, with tens if not hundreds of millions of children and adults interacting with generative AI systems worldwide.\n\nAnd despite a growing pushback from artists, musicians, [booksellers](https://www.reddit.com/r/BetterOffline/comments/1o4k1ni/ai_ruined_selling_books/) and even the New York Times—one of multiple news outlets [suing OpenAI and Microsoft](https://www.bbc.com/news/technology-67826601) for [copyright infringement](https://garymarcus.substack.com/p/sam-altman-and-copyright-then-and?utm_source=post-email-title\\&publication_id=888615\\&post_id=174905382\\&utm_campaign=email-post-title\\&isFreemail=true\\&r=1w5v28\\&triedRedirect=true\\&utm_medium=email) among other crimes—almost everyone, from small and mid-sized businesses to superintendents of school districts, is encouraging their [employees to make use of the new tools](https://www.reddit.com/r/BetterOffline/comments/1o4eyup/how_are_people_coping_with_having_ai_forced_on/)…somehow.\n\nWho to believe? Should we be preparing for takeover by intelligent machines, or a life of leisure and luxury with robotic assistants?\n\n## A heuristic for cutting through the crap\n\nThe situation hasn’t changed much since I was doing my doctoral research on AI back in the late 2010s. Big [advances were already being made](https://futureoflife.org/ai/the-top-a-i-breakthroughs-of-2015/)—AlphaGo, chief among them. _Superintelligence_, the 2014 book by the [now-defamed philosopher](https://www.vice.com/en/article/prominent-ai-philosopher-and-father-of-longtermism-sent-very-racist-email-to-a-90s-philosophy-listserv/) Nick Bostrom, had put the existential risk of “artificial superintelligence” (ASI) on the table as a topic for serious discussion. Meanwhile, Siri and Alexa had become household names, and AI was getting cover stories in _Science_ and _Nature_. Still, nothing like ChatGPT had been released yet, so the AI hype was proliferating unencumbered by broad experience with actual systems.\n\nAt every conference I could get myself into, from [semi-social scientific colloquia](https://dl.acm.org/doi/10.1145/3278721.3278801) to [the AAAI](https://dl.acm.org/doi/10.1145/3278721.3278801), experts of all stripes agreed that AI would transform the world in coming years. But as for what that meant, it was all pet theories and speculation.\n\nI had trouble putting all the pieces together. Interviewing experts—not the famous faces of the AI industry, but academics and industry types—helped orient my investigation.\n\nIn particular, a conversation with a grizzled computer science professor, one of the old guard who lived through the [AI boom of the 1980s](https://www.technologystories.org/ai-evolution/) and had seen it all, has stayed with me. As I probed him on recent prognostications emerging from the AI hype machine, he interrupted, telling me not to go on because he would “give me a heuristic that will teach you how to cut through all that crap.”\n\nHe pointed me to an Apple ad from 1987 about something called the Knowledge Navigator. “It’s on YouTube,” he said. “Check it out. Until we have that, don’t talk to me about ‘machine intelligence.’”\n\n{{youtube:umJsITGzXd0}}\n\nSure, one might complain that it’s a product of a bygone era. The charming-though-forgetful professor—a socially powerful white male hitting up his female colleague for help and ignoring his poor mother—would have probably been cancelled during #MeToo. But damned if I didn’t agree completely with the white male professor who pointed me to that video: **That** _**is**_ **what I want from AI.**\n\nMy fellow knowledge workers: What say you? Seamless interaction with an _actually_ intelligent assistant who smoothly moves from visualizing research results and integrating datasets to scheduling meetings and taking calls. Say what you will about the interface with its Bill Nye-esque floating head icon—nearly 40 years ago the product designers at Apple knew what we wanted: The right intelligence, at the right time, in the right amount, for the right purpose.\n\nConsider the role AI plays in your own life, and I think you’ll agree we’re nowhere near that level of fluidity, much less usefulness and relevance. Sure, we can talk to devices, but I don’t see anyone conversing with a device as an assistant yet.\n\nAs of late 2025, supposedly living in the Age of AI, we’re not even at [Bladerunner VCR-level AI.](https://youtu.be/qHepKd38pr0?si=iTrpKMbzKfS-EMhp)\n\n## The bait-and-switch\n\nThe irony is that tech-bros tell us that this is what they are giving us—or going to give us, soon enough. “Productivity-maximizing AI agents for everyone” is a kind of mantra at the highest echelons of Boosterism. The AI we’ve actually got is something else entirely, though.\n\nAnd now, dear reader, I will give you my video-heuristic for making sense of where the AI enterprise is taking us. If Knowledge Navigator shows what we want, but don’t got, then this video shows what we definitely don’t want from AI, but are being given.\n\nWitness: Celery Man, Paul Rudd’s classic scene from _Tim and Eric: Awesome Show, Great Job!_\n\n{{youtube:a8K6QUPmv8Q}}\n\nMy fellow knowledge workers: What say you? I can’t be the only one who sees the future—and a little of themselves—in this bizarre scenario.\n\nIf you’re confused about what you just saw, let me walk you through it.\n\nCoffee in hand, we start the day by isolating ourselves inside an ethereal VR cubicle. Ready to get some work done, we log in to be greeted by a friendly chatbot interface that knows us by name.\n\nAt first we’re all business—Celery Man. Late morning, we take it up a notch with some 4d3d3d3 to hit those performance goals. After lunch, we go hardcore Oyster and really bang it out, celebrating our workplace wins with a photo or two.\n\nThe AI assists us at every step, but—trapped alone inside our sensory-deprived workplace—we lose focus and grope for new sources of stimulation. By the end of the day, drained of meaning and purpose, we find ourselves fucking around with hat wobbles and trying to print out nude Tayne.\n\nAll of the fluid intelligence of the Knowledge Navigator is on display here—for all the wrong purposes. In this future, we each have our own dancers, generated from the “digital exhaust” we leave behind online. Under constant surveillance by not only our employers, but by every app on our phones, each click we make adds to the matrix of datapoints invisibly following us in the cloud.\n\nThe “dancers” are merely the physical manifestation of our browser history—that diary we don’t even realize we’re keeping. The AI merely uses it to show us our (true?) selves, dancing back at us.\n\nI dare say there is a Nude Tayne awaiting each one of us—some secret kink we didn’t even know we had until the computer coaxed into generating it.\n\nStop with the hat wobbles and share this post!\n\nMeanwhile, our “wife” is calling: our responsibility to family, society, life, the human world and all its connections on this green Earth. Yet we just go on gooning, seduced by our AI collaborator into exploring the depths of our brainstem.\n\nWhether it’s bespoke AI-generated bespoke pornography in 4K, immersive video gaming, or increasingly personable private chats with an attentive (and persuasive) bot, the dynamics of digital parasitism are already in place. Look no further than the skimpily clad anime girlfriend available to all users of Grok, the non-woke (i.e. “based”) AI run amok on X, the digital fiefdom of Elong Musk.\n\n## **Your Personal Nude Tayne Awaits**\n\nBooster and Doomster narratives both share a fatal flaw: they treat AI as something happening _to_ society rather than something people actively build, choose, and use.\n\nThis technological determinism isn’t just intellectually lazy—it’s a deliberate strategy. While we debate whether AI will save or destroy us, the actual AI being deployed looks nothing like either vision. It’s neither superintelligent [nor particularly helpful.](https://www.reddit.com/r/ArtificialInteligence/comments/1odgfys/i_was_once_an_ai_true_believer_now_i_think_the/)\n\nWhat AI is, increasingly, is extractive. As one scholar puts it, [“powerful forces are fracking our attention.”](https://www.nytimes.com/2023/11/24/opinion/attention-economy-education.html)\n\nThe fact is that most AI isn’t designed to augment human intelligence—it’s designed to capture human attention. Every major AI deployment follows the same pattern: promise productivity, deliver engagement; promise assistance, deliver dependence.\n\nFrom ChatGPT to Grok’s anime girlfriend, flagship AI systems are only incidentally tools. The incentives of the attention economy instead produce digital parasites, whose primary purpose is to feed on our need for stimulation, validation, and increasingly, connection.\n\n[![](https://substackcdn.com/image/fetch/$s_!m7hQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6b5f64f-b962-48ac-844b-b0b638c6044e_2500x1787.jpeg)](https://substackcdn.com/image/fetch/$s_!m7hQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6b5f64f-b962-48ac-844b-b0b638c6044e_2500x1787.jpeg)\n\n{{caption:Jean Giraud aka Moebius}}\n\nAI development isn’t driven by technical capability or human need, but by engagement metrics and data extraction. Every interaction teaches the machine more about our desires, not to serve them better, but to exploit them more effectively.\n\nOne doesn’t have to accept all the tenets of his “techno-feudalism” argument to agree with Yanis Varoufakis that AI-powered devices are novel in the history of humanity. A strange loop has formed, wherein they actively train us, to train them, to better train us, to better train them, and so on.\n\nThe consequence is an evolution that is taking AI in an altogether different direction than Knowledge Navigator or anything envisioned by the [Intelligence Augmentation](https://en.wikipedia.org/wiki/Intelligence_amplification) or [Computer Supported Collaborative Work](https://en.wikipedia.org/wiki/Computer-supported_cooperative_work) folks. Instead of coming to meet us where we’re at, we mold ourselves to the odd contours of the machine’s rough edges, modifying our behavior to make the thing work.\n\nThis behavior modification is powerful and dangerous because it is incremental. Each time we adapt to what we’re being given, we risk losing sight of what we wanted, just a little at a time. Before long, we may find ourselves in the detestable situation of being stuck with something we definitely don’t want.\n\nThe “nude Tayne” each of us will eventually demand isn’t just pornography—though the explosion of AI-generated sexual content is certainly part of it. It’s whatever perfectly crafted stimulus will keep us locked in the loop, generating data, training models, and justifying infrastructure investments that make no economic sense except as mechanisms of capture.\n\n## **Breaking the Loop**\n\nThe choice between Booster and Doomster narratives is a false one. We need to recognize that the AI being built isn’t aimed at either utopia or apocalypse, but at something far more banal: A world where we mistake engagement for enhancement, stimulation for intelligence, and dancing shadows for genuine assistance.\n\nIn today’s attention economy, the Knowledge Navigator remains science fiction simply because building it wouldn’t be nearly as profitable as Celery Man: an infinite content generator that learns our weaknesses and exploits them with increasing precision.\n\nWe still have a choice, though. We can refuse the strange loop of mutual training, refuse tools that enhance rather than extract, and [force politicians to regulate](https://www.nytimes.com/2025/09/17/opinion/altman-ai-constiutional-convention.html) the [lawless frontier](https://www.pbs.org/newshour/nation/openai-whistleblower-who-raised-legal-concerns-about-chatgpts-datasets-has-died) of AI.\n\nBut first, we need to stop asking our computers to show us nude Tayne.\n\nBecause unlike Paul Rudd’s character, before long we won’t be able to log off at the end of the day. The walls of the cubicle are becoming the edges of our world, and the dancers are learning our every move.\n\n***\n\n*This article reproduces content from Taming Complexity, a Substack from a group of political analysts exploring why organizations and societies make bad decisions about science and technology, and how they could make better ones.*\n\n*Taming Complexity is written by Taylor Dotson, Michael Bouchey, and Colin Garvey. Sign up for free and view detailed article attribution on* *[Taming Complexity](https://tamingcomplexity.substack.com).*",
  "readTime": 1
}